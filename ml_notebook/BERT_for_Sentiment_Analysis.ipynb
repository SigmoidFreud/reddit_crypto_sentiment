{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_lTXsMK3sNYr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import spacy\n",
    "from nltk.stem.porter import *\n",
    "from transformers import BertTokenizer\n",
    "from spacy.lang.en import English\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u07WRKnxsX96"
   },
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1_Tpie3tGp3"
   },
   "source": [
    "### 2.1. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_tOJXeR9sx57"
   },
   "outputs": [],
   "source": [
    "lm = spacy.load(\"en_core_web_sm\")\n",
    "# Download data\n",
    "data_set_url = 'https://gist.githubusercontent.com/flotothemoon/e060935138f5686efae6911bce45e7b3/raw/01639ea1a43505c0be35b32a6e1798ec32360037/crypto_reddit_sentiment.csv'\n",
    "df = pd.read_csv(data_set_url)\n",
    "df['Sentiment'].replace(to_replace=['Positive', 'Negative'], value=[1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVkXcFzrtREn"
   },
   "source": [
    "### 2.2. Load Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp-vfxKZvl6M"
   },
   "source": [
    "We will randomly split the entire training data into two sets: a train set with 80% of the data and a validation set with 20% of the data. We will perform hyperparameter tuning using cross-validation on the train set and use the validation set to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X4HKAFTbvMwI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Comment Text']\n",
    "y = df['Sentiment']\n",
    "\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X79dYY3sxDCi"
   },
   "source": [
    "## 3. Set up GPU for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi1CoEOL1puh"
   },
   "source": [
    "Google Colab offers free GPUs and TPUs. Since we'll be training a large neural network it's best to utilize these features.\n",
    "\n",
    "A GPU can be added by going to the menu and selecting:\n",
    "\n",
    "`Runtime -> Change runtime type -> Hardware accelerator: GPU`\n",
    "\n",
    "Then we need to run the following cell to specify the GPU as the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "K7hxtI4l0SUJ",
    "outputId": "2a92de7e-c2a2-4ad8-d2a8-94638165b9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n",
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEPPYHa62JXF"
   },
   "source": [
    "# D - Fine-tuning BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4sXctSh4sq0"
   },
   "source": [
    "## 2. Tokenization and Input Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygbZpK6qbIYE"
   },
   "source": [
    "Before tokenizing our text, we will perform some slight processing on our text including removing entity mentions (eg. @united) and some special character. The level of processing here is much less than in previous approachs because BERT was trained with the entire sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4L_Rc7l4bgzJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Valued\n",
      "[nltk_data]     Customer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Valued\n",
      "[nltk_data]     Customer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    my_doc = lm(text)\n",
    "\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    filtered_sentence = []\n",
    "\n",
    "    for word in token_list:\n",
    "        lexeme = lm.vocab[word]\n",
    "        if not lexeme.is_stop:\n",
    "            filtered_sentence.append(word)\n",
    "    stemmer = PorterStemmer()\n",
    "    text = ' '.join([stemmer.stem(y) for y in filtered_sentence])\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3acv6s95YYr"
   },
   "source": [
    "### 2.1. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1fRHtdU5dEn"
   },
   "source": [
    "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\n",
    "\n",
    "In addition, we are required to add special tokens to the start and end of each sentence, pad & truncate all sentences to a single constant length, and explicitly specify what are padding tokens with the \"attention mask\".\n",
    "\n",
    "The `encode_plus` method of BERT tokenizer will:\n",
    "\n",
    "(1) split our text into tokens,\n",
    "\n",
    "(2) add the special `[CLS]` and `[SEP]` tokens, and\n",
    "\n",
    "(3) convert these tokens into indexes of the tokenizer vocabulary,\n",
    "\n",
    "(4) pad or truncate sentences to max length, and\n",
    "\n",
    "(5) create attention mask.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "463"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "463"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_comment_length(data, nlp=lm):\n",
    "    max_len = -float('inf')\n",
    "    for text in data['Comment Text']:\n",
    "        my_doc = lm(text)\n",
    "        \n",
    "        # Create list of word tokens\n",
    "        token_list = []\n",
    "        for token in my_doc:\n",
    "            token_list.append(token.text)\n",
    "        filtered_sentence = []\n",
    "        \n",
    "        for word in token_list:\n",
    "            lexeme = nlp.vocab[word]\n",
    "            if not lexeme.is_stop:\n",
    "                filtered_sentence.append(word)\n",
    "        max_len = max(len(filtered_sentence), max_len)\n",
    "    return max_len\n",
    "\n",
    "max_len = get_max_comment_length(df)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "961b5b49f3cf4828ba3510d721bd57db",
      "30cb683585664b7a95ddd24de514c103",
      "a65ea33fe937416bbc29cbebdb025f93",
      "7257f203a0de462789458073993d9948",
      "527af73b1cdd4f3ba035daceb641ad78",
      "fdb8ea4ab0814e6da137331241694bdf",
      "8a7c1e4357444b92bb9821a07cd693ae",
      "dc7f6589b9be45c5b89a1a088ff5d375"
     ]
    },
    "id": "yDAfbCle59tP",
    "outputId": "253338f0-2440-42b3-c4e8-66287d57773a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data, max_len=max_len):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=max_len,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "QTlQzTzAfCy7",
    "outputId": "933db5ca-b529-4ec9-cdda-e94851f7dc73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Valued Customer\\anaconda3new\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I bought 2200 at the ico, at 0.50$ per coin. Hold everything and sold it 3 months ago and it helped me to buy a bigger house.\n",
      "Token IDs:  [101, 4149, 10545, 2692, 24582, 2080, 1010, 1014, 1012, 2753, 1002, 9226, 1012, 2907, 2853, 1017, 3204, 3283, 2393, 4965, 7046, 7570, 2271, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I bought 2200 at the ico, at 0.50$ per coin. Hold everything and sold it 3 months ago and it helped me to buy a bigger house.\n",
      "Token IDs:  [101, 4149, 10545, 2692, 24582, 2080, 1010, 1014, 1012, 2753, 1002, 9226, 1012, 2907, 2853, 1017, 3204, 3283, 2393, 4965, 7046, 7570, 2271, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZU8t5VNfvhY"
   },
   "source": [
    "### 2.2. Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoHdl3gFgMZY"
   },
   "source": [
    "We will create an iterator for our dataset using the torch DataLoader class. This will help save on memory during training and boost the training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xHuYEc61gcGL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36     0\n",
      "110    0\n",
      "32     0\n",
      "370    1\n",
      "449    1\n",
      "      ..\n",
      "160    1\n",
      "157    0\n",
      "91     0\n",
      "323    1\n",
      "392    1\n",
      "Name: Sentiment, Length: 449, dtype: int64\n",
      "36     0\n",
      "110    0\n",
      "32     0\n",
      "370    1\n",
      "449    1\n",
      "      ..\n",
      "160    1\n",
      "157    0\n",
      "91     0\n",
      "323    1\n",
      "392    1\n",
      "Name: Sentiment, Length: 449, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "print(y_train)\n",
    "train_labels = torch.tensor(np.array(y_train))\n",
    "val_labels = torch.tensor(np.array(y_val))\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSRAga-yj17q"
   },
   "source": [
    "## 3. Train Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoOdsDgG8b_Z"
   },
   "source": [
    "### 3.1. Create BertClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA_yESCl5nuK"
   },
   "source": [
    "BERT-base consists of 12 transformer layers, each transformer layer takes in a list of token embeddings, and produces the same number of embeddings with the same hidden size (or dimensions) on the output. The output of the final transformer layer of the `[CLS]` token is used as the features of the sequence to feed a classifier.\n",
    "\n",
    "The `transformers` library has the [`BertForSequenceClassification`](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification) class which is designed for classification tasks. However, we will create a new class so we can specify our own choice of classifiers.\n",
    "\n",
    "Below we will create a BertClassifier class with a BERT model to extract the last hidden layer of the `[CLS]` token and a single-hidden-layer feed-forward neural network as our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "YK41aBFSj5jK",
    "outputId": "ce7e0b40-5790-47ff-8c85-edda7ed9a6cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwNrCgPh-yR7"
   },
   "source": [
    "### 3.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6iOXiN8-8gc"
   },
   "source": [
    "To fine-tune our Bert Classifier, we need to create an optimizer. The authors recommend following hyper-parameters:\n",
    "\n",
    "- Batch size: 16 or 32\n",
    "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
    "- Number of epochs: 2, 3, 4\n",
    "\n",
    "Huggingface provided the [run_glue.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109) script, an examples of implementing the `transformers` library. In the script, the AdamW optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JX7su7Q_269U"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41DRNjv4B0Ow"
   },
   "source": [
    "### 3.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYU-GQRZG0y8"
   },
   "source": [
    "We will train our Bert Classifier for 4 epochs. In each epoch, we will train our model and evaluate its performance on the validation set. In more details, we will:\n",
    "\n",
    "Training:\n",
    "- Unpack our data from the dataloader and load the data onto the GPU\n",
    "- Zero out gradients calculated in the previous pass\n",
    "- Perform a forward pass to compute logits and loss\n",
    "- Perform a backward pass to compute gradients (`loss.backward()`)\n",
    "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "- Update the model's parameters (`optimizer.step()`)\n",
    "- Update the learning rate (`scheduler.step()`)\n",
    "\n",
    "Evaluation:\n",
    "- Unpack our data and load onto the GPU\n",
    "- Forward pass\n",
    "- Compute loss and accuracy rate over the validation set\n",
    "\n",
    "The script below is commented with the details of our training and evaluation loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Xy4HkhyECibW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSfTy9LqiFD-"
   },
   "source": [
    "Now, let's start training our BertClassifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574,
     "referenced_widgets": [
      "b7ce4c3233df4adfb0e914d5a445a019",
      "d581b0e01f654ac0b503fd58c5288348",
      "18d585f78629424fa2fc61feb2c2fd3a",
      "b0f389b162c94eb1b424e9c50092ec4c",
      "96ec7e0964e24e7da6c64d65ecc195e1",
      "280acaefa8d84013b50ed9238965b8e0",
      "e7f104c91014475cab28e59183a1ec1b",
      "308be4f1105141a2ac9885758d1dd1f2",
      "9b27ad8651b5415f93c401d5cda4a080",
      "9b298e31e3be4fcb96f83ef18a66b87a",
      "8f66a780bcc84b9fb14794cf3934408a",
      "eb8c20e05f204a97a06f5bd6284a0775",
      "47e45c9730574e15a7eeca7fddc99732",
      "b84700dfac5f4ad4b3100622a6148484",
      "af4d474d40af4605be6a399f920b134f",
      "28bb56ade0004bbd8f41916d4b27df40"
     ]
    },
    "id": "wfYw7dJ0U0v6",
    "outputId": "80f02200-4234-41de-dfd8-0a98e8fb6d32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Valued Customer\\anaconda3new\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   14    |   0.693640   |     -      |     -     |  1454.09 \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.693640   |  0.717154  |   42.51   |  1608.57 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   14    |   0.632259   |     -      |     -     |  1380.92 \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.632259   |  0.597742  |   68.52   |  1535.90 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   14    |   0.478256   |     -      |     -     |  1387.21 \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.478256   |  0.428780  |   81.53   |  1517.56 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   14    |   0.332577   |     -      |     -     |  1363.22 \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.332577   |  0.311345  |   92.28   |  1494.65 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5ostg9kPlra"
   },
   "source": [
    "### 3.4. Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIlSTDA7Z9DF"
   },
   "source": [
    "The prediction step is similar to the evaluation step that we did in the training loop, but simpler. We will perform a forward pass to compute logits and apply softmax to calculate probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "V5_w4erqGzpe"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "kcmj5s0eRMUh",
    "outputId": "ca3adcfc-e833-462c-9368-b5d87905dca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9526\n",
      "Accuracy: 92.04%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18d585f78629424fa2fc61feb2c2fd3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_280acaefa8d84013b50ed9238965b8e0",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_96ec7e0964e24e7da6c64d65ecc195e1",
      "value": 361
     }
    },
    "280acaefa8d84013b50ed9238965b8e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28bb56ade0004bbd8f41916d4b27df40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "308be4f1105141a2ac9885758d1dd1f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30cb683585664b7a95ddd24de514c103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e45c9730574e15a7eeca7fddc99732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "527af73b1cdd4f3ba035daceb641ad78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7257f203a0de462789458073993d9948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc7f6589b9be45c5b89a1a088ff5d375",
      "placeholder": "",
      "style": "IPY_MODEL_8a7c1e4357444b92bb9821a07cd693ae",
      "value": " 232k/232k [00:00&lt;00:00, 632kB/s]"
     }
    },
    "8a7c1e4357444b92bb9821a07cd693ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f66a780bcc84b9fb14794cf3934408a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b84700dfac5f4ad4b3100622a6148484",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47e45c9730574e15a7eeca7fddc99732",
      "value": 440473133
     }
    },
    "961b5b49f3cf4828ba3510d721bd57db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a65ea33fe937416bbc29cbebdb025f93",
       "IPY_MODEL_7257f203a0de462789458073993d9948"
      ],
      "layout": "IPY_MODEL_30cb683585664b7a95ddd24de514c103"
     }
    },
    "96ec7e0964e24e7da6c64d65ecc195e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9b27ad8651b5415f93c401d5cda4a080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f66a780bcc84b9fb14794cf3934408a",
       "IPY_MODEL_eb8c20e05f204a97a06f5bd6284a0775"
      ],
      "layout": "IPY_MODEL_9b298e31e3be4fcb96f83ef18a66b87a"
     }
    },
    "9b298e31e3be4fcb96f83ef18a66b87a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a65ea33fe937416bbc29cbebdb025f93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdb8ea4ab0814e6da137331241694bdf",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_527af73b1cdd4f3ba035daceb641ad78",
      "value": 231508
     }
    },
    "af4d474d40af4605be6a399f920b134f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0f389b162c94eb1b424e9c50092ec4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_308be4f1105141a2ac9885758d1dd1f2",
      "placeholder": "",
      "style": "IPY_MODEL_e7f104c91014475cab28e59183a1ec1b",
      "value": " 361/361 [00:03&lt;00:00, 113B/s]"
     }
    },
    "b7ce4c3233df4adfb0e914d5a445a019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18d585f78629424fa2fc61feb2c2fd3a",
       "IPY_MODEL_b0f389b162c94eb1b424e9c50092ec4c"
      ],
      "layout": "IPY_MODEL_d581b0e01f654ac0b503fd58c5288348"
     }
    },
    "b84700dfac5f4ad4b3100622a6148484": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d581b0e01f654ac0b503fd58c5288348": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc7f6589b9be45c5b89a1a088ff5d375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7f104c91014475cab28e59183a1ec1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb8c20e05f204a97a06f5bd6284a0775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28bb56ade0004bbd8f41916d4b27df40",
      "placeholder": "",
      "style": "IPY_MODEL_af4d474d40af4605be6a399f920b134f",
      "value": " 440M/440M [01:15&lt;00:00, 5.81MB/s]"
     }
    },
    "fdb8ea4ab0814e6da137331241694bdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
